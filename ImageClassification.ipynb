{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageClassification.ipynb","provenance":[],"private_outputs":true,"mount_file_id":"1_1nmiRKsfXDCzNTlopfLDEoAUOtsLWw4","authorship_tag":"ABX9TyPK6/P/BXT9DMRP6MEf3HXy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x_f-_0r5uw7x"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["## Basic Cat and Dog Classifier in TF and Keras"],"metadata":{"id":"XRDnr90R7qzR"}},{"cell_type":"code","source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n","    -O /tmp/cats_and_dogs_filtered.zip"],"metadata":{"id":"0FRHj8ww7bWs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import zipfile\n","local_zip = '/content/drive/MyDrive/Colab Notebooks/Enhance IT/Image Processing/cats_and_dogs_filtered.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/content/drive/MyDrive/Colab Notebooks/Enhance IT/Image Processing')\n","zip_ref.close()"],"metadata":{"id":"BL0wtZ_P77CT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_dir='/content/drive/MyDrive/Colab Notebooks/Enhance IT/Image Processing/cats_and_dogs_filtered'\n","train_dir=os.path.join(base_dir,'train')\n","validation_dir=os.path.join(base_dir, 'validation')"],"metadata":{"id":"ER-XiVVu84Eh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_cats_dir=os.path.join(train_dir, 'cats')\n","train_dogs_dir=os.path.join(train_dir, 'dogs')\n","validation_cats_dir=os.path.join(validation_dir, 'cats')\n","validation_dogs_dir=os.path.join(validation_dir, 'dogs')"],"metadata":{"id":"2rReG6XC9oDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.image as mpimg"],"metadata":{"id":"WpMXbXZH9-E8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_cat_fnames = os.listdir(train_cats_dir)\n","train_dog_fnames = os.listdir(train_dogs_dir)\n","\n","nrows = 4\n","ncols = 4\n","fig = plt.gcf()\n","fig.set_size_inches(ncols*4, nrows*4)\n","\n","pic_index = 8\n","next_cat = [os.path.join(train_cats_dir, fname) for fname in train_cat_fnames[pic_index-8:pic_index]]\n","next_dog = [os.path.join(train_dogs_dir, fname) for fname in train_dog_fnames[pic_index-8:pic_index]]\n","\n","for i, img_path in enumerate(next_cat+next_dog):\n","  sp=plt.subplot(nrows, ncols, i+1)\n","  sp.axis('Off')\n","  img=mpimg.imread(img_path)\n","  plt.imshow(img)"],"metadata":{"id":"xUSGc40k-IWf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build CNN in Keras"],"metadata":{"id":"F2Xrh7h2BrCZ"}},{"cell_type":"code","source":["from tensorflow.keras import layers\n","from tensorflow.keras import Model"],"metadata":{"id":"wURO77t1_mJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_input = layers.Input(shape=(150,150,3))\n","L = layers.Conv2D(16,3, activation='relu')(img_input)\n","L = layers.MaxPooling2D(2)(L)\n","\n","L = layers.Conv2D(32,3,activation='relu')(L)\n","L = layers.MaxPooling2D(2)(L)\n","\n","L = layers.Conv2D(64,3,activation='relu')(L)\n","L = layers.MaxPooling2D(2)(L)"],"metadata":{"id":"CPB3Z5WgBwEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FULL CONECTION\n","\n","F = layers.Flatten()(L)\n","F = layers.Dense(512, activation='relu')(F)\n","output = layers.Dense(1, activation='sigmoid')(F)"],"metadata":{"id":"ePyIbHu7Ea6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# BUILD MODEL\n","\n","model = Model(img_input, output)\n","model.summary()"],"metadata":{"id":"7axejtClFFzw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import RMSprop"],"metadata":{"id":"GoqPK_ZZF3FV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy',optimizer=RMSprop(learning_rate=0.001), metrics=['acc'])"],"metadata":{"id":"SDcX3VJzGO54"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data Preparation\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"I-EZ6zlTHK3n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Rescaling\n","\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(150,150),\n","    batch_size=20,\n","    class_mode='binary')\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(150,150),\n","    batch_size=20,\n","    class_mode='binary')"],"metadata":{"id":"8AODgDYDHl9W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=100,\n","    epochs=15,\n","    validation_data=validation_generator,\n","    validation_steps=50, verbose=2)"],"metadata":{"id":"eOc5GS93JS_h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Image Classification with VGG16 and Data Augmentation"],"metadata":{"id":"45u_Z6vL7NAs"}},{"cell_type":"code","source":["BATCH_Size = 20\n","IMG_SHAPE = 150 # Our training data consists of images with width of 150 pixels and height of 150 pixels"],"metadata":{"id":"T1R2OJfy6TeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n","def plotImages(images_arr):\n","  fig, axes = plt.subplots(1,5,figsize=(20,20))\n","  axes = axes.flatten()\n","  for img, ax in zip(images_arr, axes):\n","    ax.imshow(img)\n","  plt.tight_layout()\n","  plt.show()\n"],"metadata":{"id":"jRktFwdV7YHf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_gen_train = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')"],"metadata":{"id":"24sAsymg8HIN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_gen = image_gen_train.flow_from_directory(\n","    batch_size=BATCH_Size,\n","    directory=train_dir,\n","    shuffle=True,\n","    target_size=(IMG_SHAPE,IMG_SHAPE),\n","    class_mode='binary'\n",")"],"metadata":{"id":"rTPSecsu9IGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["augmented_Im=[train_data_gen[0][0][0]for i in range(10)]\n","plotImages(augmented_Im)"],"metadata":{"id":"yu_VxIZS-nKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_gen_val= ImageDataGenerator(rescale=1./255)\n","val_data_gen = image_gen_val.flow_from_directory(\n","    batch_size=BATCH_Size,\n","    directory = validation_dir,\n","    target_size=(IMG_SHAPE,IMG_SHAPE),\n","    class_mode = 'binary'\n",")"],"metadata":{"id":"_y5z78zW-z7u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["INPUT_SHAPE=(150,150,3)"],"metadata":{"id":"mZdfuLigGMcR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Loading VGG16"],"metadata":{"id":"XTKPQRnmGZtS"}},{"cell_type":"code","source":["from keras.applications import vgg16\n","import tensorflow as tf\n","import keras"],"metadata":{"id":"yJRSMLO7Gd7h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg = vgg16.VGG16(include_top = False, weights='imagenet', input_shape = INPUT_SHAPE)\n","output = vgg.layers[-1].output\n","output = tf.keras.layers.Flatten()(output)\n","vgg_model = Model(vgg.input, output)"],"metadata":{"id":"pX7AzEBSGrt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg_model.trainable = False\n","for layer in vgg_model.layers:\n","  layer.trainable = False"],"metadata":{"id":"FzFvTr8XJ-Y9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras import optimizers\n","from keras.layers import Flatten,Dropout,Dense"],"metadata":{"id":"SO_NrUsqKRHX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()"],"metadata":{"id":"zknUJ_P5Ke1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(vgg_model)\n","model.add(Flatten())\n","model.add(Dense(512, activation = 'relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation = 'sigmoid'))"],"metadata":{"id":"NyxfmQnMKnS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n","model.summary()"],"metadata":{"id":"NQCpLoxJNkbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg_model.summary()"],"metadata":{"id":"6GVfapTCOdw1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=0.0005),metrics=['accuracy'])"],"metadata":{"id":"UFIuf206QaHO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit_generator(train_data_gen, steps_per_epoch=100, epochs=10, validation_data = val_data_gen, validation_steps=50, callbacks=[callback],verbose=2)"],"metadata":{"id":"5F2Ev0wQQ_Cm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, image"],"metadata":{"id":"6UZYRLfYdcxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(10)\n","\n","plt.figure(figsize=(20, 12))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"WRO28KDyWPHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(file):\n","  img = image.load_img(file, target_size = (IMG_SHAPE, IMG_SHAPE))\n","  img = img_to_array(img)\n","  img = np.expand_dims(img, axis=0)\n","  print (img)\n","\n","\n","  #img = preprocess_input(img)\n","  probs = model.predict(img)\n","  print(probs)\n","  \n","  if probs[0][0]==1:\n","    result = 'dog'\n","  else: result = 'cat'\n","\n","  pic = plt.imread(file)\n","  plt.imshow(pic)\n","  plt.show()\n","  print(\"This is a picture of a \"+result+\"!\")\n","  return result"],"metadata":{"id":"1BX800ALcI8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict('/content/drive/MyDrive/Colab Notebooks/Enhance IT/Image Processing/Dalmata.jpg')"],"metadata":{"id":"hduSenKl4lpa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict('/content/drive/MyDrive/Colab Notebooks/Enhance IT/Image Processing/Angry Dog.jpg')"],"metadata":{"id":"RMgsgaxwdlmt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict('/content/drive/MyDrive/Colab Notebooks/Enhance IT/Image Processing/cat-its-mouth-open.jpg')"],"metadata":{"id":"UeHwanps4ryE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict('/content/drive/MyDrive/Colab Notebooks/Enhance IT/Image Processing/egypt_kitty_social.jpg')"],"metadata":{"id":"_kdmIuSO4xpb"},"execution_count":null,"outputs":[]}]}